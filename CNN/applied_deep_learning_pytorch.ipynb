{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cvl70wWq00VO"
   },
   "source": [
    "# Fine tunning for flower dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7xZk8VJ0zaa"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-of9HBH1Y-r"
   },
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbCSoB5Q1XYr",
    "outputId": "2ee95d46-747f-4a4a-950f-da1764bddf68"
   },
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9y0GuVN18eC"
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "def members(tf, folder):\n",
    "  paths = [folder + '/' + str(i) + \"/\" for i in range(1, 6)]\n",
    "  for member in tf.getmembers():\n",
    "    for p in paths:\n",
    "      if member.path.startswith(p):\n",
    "        yield member\n",
    "\n",
    "with tarfile.open(\"flower_data.tar.gz\") as tar:\n",
    "    tar.extractall(members=members(tar, \"train\"))\n",
    "\n",
    "with tarfile.open(\"flower_data.tar.gz\") as tar:\n",
    "    tar.extractall(members=members(tar, \"valid\"))\n",
    "\n",
    "with tarfile.open(\"flower_data.tar.gz\") as tar:\n",
    "    tar.extractall(members=members(tar, \"test\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gLQcHAtX6pE4"
   },
   "outputs": [],
   "source": [
    "# setup directory\n",
    "train_dir = 'train'\n",
    "valid_dir = 'valid'\n",
    "test_dir = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "O2v_UvL17Fw4",
    "outputId": "67e97118-b989-4f43-bbbd-8ddbcb827cca"
   },
   "outputs": [],
   "source": [
    "image_path = train_dir + '/1/image_06734.jpg'\n",
    "img = Image.open(image_path)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRQJCqom71TZ"
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcGmYemU8RNM"
   },
   "source": [
    "### Transform data\n",
    "\n",
    "The dataset is split into three parts, training, validation, and testing. For the training, you’ll want to apply transformations such as random scaling, cropping, and flipping. This will help the network generalize leading to better performance. You’ll also need to make sure the input data is resized to 224x224 pixels as required by the pre-trained networks.\n",
    "\n",
    "The validation and testing sets are used to measure the model’s performance on data it hasn’t seen yet. For this you don’t want any scaling or rotation transformations, but you’ll need to resize then crop the images to the appropriate size.\n",
    "\n",
    "The pre-trained networks you’ll use were trained on the ImageNet dataset where each color channel was normalized separately. For all three sets you’ll need to normalize the means and standard deviations of the images to what the network expects. For the means, it’s [0.485, 0.456, 0.406] and for the standard deviations [0.229, 0.224, 0.225], calculated from the ImageNet images. These values will shift each color channel to be centered at 0 and range from -1 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZh0fovI9DGO"
   },
   "source": [
    "Below, we apply the following transformations:\n",
    "\n",
    "*   ToTensor: Converts the image to a pytorch tensor\n",
    "*   RandomHorizontalFlip: Flips the image to give more variety to the network\n",
    "*   RandomReziedCrop: Crops the image to size 224 x 224 pixels\n",
    "*   Normalize: Sets the color channel for each pixel to somewhere between -1 and 1.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zdj9mRh07q8d"
   },
   "outputs": [],
   "source": [
    "###Transform data\n",
    "data_transforms = {\n",
    "    'training' : transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                    transforms.RandomHorizontalFlip(),transforms.RandomRotation(30),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                         [0.229, 0.224, 0.225])]),\n",
    "                                                            \n",
    "    'validation' : transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                           [0.229, 0.224, 0.225])]),\n",
    "\n",
    "    'testing' : transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "}\n",
    "\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "image_datasets = {\n",
    "    'training' : datasets.ImageFolder(train_dir, transform=data_transforms['training']),\n",
    "    'testing' : datasets.ImageFolder(test_dir, transform=data_transforms['testing']),\n",
    "    'validation' : datasets.ImageFolder(valid_dir, transform=data_transforms['validation'])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNEGuNQh83fK"
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMQZRWqE85uM"
   },
   "outputs": [],
   "source": [
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "dataloaders = {\n",
    "    'training' : torch.utils.data.DataLoader(image_datasets['training'], batch_size=64, shuffle=True),\n",
    "    'testing' : torch.utils.data.DataLoader(image_datasets['testing'], batch_size=64, shuffle=False),\n",
    "    'validation' : torch.utils.data.DataLoader(image_datasets['validation'], batch_size=64, shuffle=True)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0t9eYq0--wkN"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aujw4OWB-szt"
   },
   "outputs": [],
   "source": [
    "def train(model, epochs, learning_rate, criterion, optimizer, training_loader, validation_loader):\n",
    "    \n",
    "    model.train() # Puts model into training mode\n",
    "    print_every = 40\n",
    "    steps = 0\n",
    "    use_gpu = False\n",
    "    \n",
    "    # Check to see whether GPU is available\n",
    "    if torch.cuda.is_available():\n",
    "        use_gpu = True\n",
    "        model.cuda()\n",
    "    else:\n",
    "        model.cpu()\n",
    "    \n",
    "    # Iterates through each training pass based on #epochs & GPU/CPU\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for inputs, labels in iter(training_loader):\n",
    "            steps += 1\n",
    "\n",
    "            if use_gpu:\n",
    "                inputs = Variable(inputs.float().cuda())\n",
    "                labels = Variable(labels.long().cuda()) \n",
    "            else:\n",
    "                inputs = Variable(inputs)\n",
    "                labels = Variable(labels) \n",
    "\n",
    "            # Forward and backward passes\n",
    "            optimizer.zero_grad() # zero's out the gradient, otherwise will keep adding\n",
    "            output = model.forward(inputs) # Forward propogation\n",
    "            loss = criterion(output, labels) # Calculates loss\n",
    "            loss.backward() # Calculates gradient\n",
    "            optimizer.step() # Updates weights based on gradient & learning rate\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                validation_loss, accuracy = validate(model, criterion, validation_loader)\n",
    "\n",
    "                print(\"Epoch: {}/{} \".format(epoch+1, epochs),\n",
    "                        \"Training Loss: {:.3f} \".format(running_loss/print_every),\n",
    "                        \"Validation Loss: {:.3f} \".format(validation_loss),\n",
    "                        \"Validation Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brh6gWUx_Chp"
   },
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOnXlyHl_GgE"
   },
   "outputs": [],
   "source": [
    "def validate(model, criterion, data_loader):\n",
    "    model.eval() # Puts model into validation mode\n",
    "    accuracy = 0\n",
    "    test_loss = 0\n",
    "    \n",
    "    for inputs, labels in iter(data_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = Variable(inputs.float().cuda(), volatile=True)\n",
    "            labels = Variable(labels.long().cuda(), volatile=True) \n",
    "        else:\n",
    "            inputs = Variable(inputs, volatile=True)\n",
    "            labels = Variable(labels, volatile=True)\n",
    "\n",
    "        output = model.forward(inputs)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "        ps = torch.exp(output).data \n",
    "        equality = (labels.data == ps.max(1)[1])\n",
    "        accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "\n",
    "    return test_loss/len(data_loader), accuracy/len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxjb2XZJ-FCO"
   },
   "source": [
    "# Activity 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rqg7pMnK-O2H"
   },
   "source": [
    "Create your own model and evaluate its performance\n",
    "\n",
    "(Look at activity from CNN class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QSsOgnd-Gqp"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(256*28*28, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 5))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_CYkzFgN_hZV"
   },
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "epochs = 9\n",
    "learning_rate = 0.001\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train(model, epochs, learning_rate, criterion, optimizer, dataloaders['training'], dataloaders['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8so30Ja1AruY"
   },
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 889,
     "referenced_widgets": [
      "949ee989a20345ccb165075da7d1caec",
      "20b78c3161d7493ba26762ad7f8e5969",
      "0c7c3cb36f714c41a242f4f467acdf6f",
      "f88cfb35a12742deb5e1cedc17c8ab11",
      "8c9ced6d0d834d7793d75e572f640187",
      "0433aa4ac87d4816ab0b9e4d78e905a0",
      "2d78dfa173e94d07b83f91afa43abe04",
      "faa72dcc176146b394c219898ccda2fe",
      "264f02c1f4084040ba663543f17c9c4e",
      "e1dd4b281da540eda30bf2186ec10eb0",
      "5b877c3e81cd43a4818268074831b9fb"
     ]
    },
    "id": "aSQ5h5OKA0UC",
    "outputId": "2dd942e9-0a58-4fea-90cf-db01d4f52172"
   },
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S35sY034BFQm"
   },
   "source": [
    "In the classifier, the first line (0): Linear(in_features=25088) indicates that it’s expecting 25088 inputs into the first layer. When we define our own classifier below, we will keep this input size. However, we will need to adjust the last output to match the number of categories we have. In this case 5 flower species. We use ReLU activation functions at each hidden layer, and then apply a Softmax loss function to calculate error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ExPAo2KBBL1F"
   },
   "outputs": [],
   "source": [
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(25088, 4096)), # First layer\n",
    "                          ('relu', nn.ReLU()), # Apply activation function\n",
    "                          ('fc2', nn.Linear(4096, 5)), # Output layer\n",
    "                          ('output', nn.LogSoftmax(dim=1)) # Apply loss function\n",
    "                          ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIn1DRmwBjHd"
   },
   "source": [
    "We don’t want to udpate the weights of our pretrained model, just the classifier. So we can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j1pAZdktBjnz"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcGOMktyBlzU"
   },
   "source": [
    "Next, we replace the classifier in the model with the one we just built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AnZ6wgE5Bnjz"
   },
   "outputs": [],
   "source": [
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nnjGKC8sBu7p"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)\n",
    "train(model, epochs, learning_rate, criterion, optimizer, dataloaders['training'], dataloaders['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSvtip7bB9Ld"
   },
   "source": [
    "# Activites 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRoRiVbwCDHw"
   },
   "source": [
    "**Try doing fine-tunning instead of freezing. Does it increase performance?** You need to use a much smaller learning rate for Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_LRhwgCCJn6"
   },
   "outputs": [],
   "source": [
    "# Your code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UUGJmeECMJ3"
   },
   "source": [
    "#Activity 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijGxHUneCOXO"
   },
   "source": [
    "**Try with Inception3 instead of VGG16. Do you see differences in performance?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yNHECf1CTJ_"
   },
   "outputs": [],
   "source": [
    "# Your code below"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": " applied_deep_learning_pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0433aa4ac87d4816ab0b9e4d78e905a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c7c3cb36f714c41a242f4f467acdf6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_faa72dcc176146b394c219898ccda2fe",
      "max": 553433881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_264f02c1f4084040ba663543f17c9c4e",
      "value": 553433881
     }
    },
    "20b78c3161d7493ba26762ad7f8e5969": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0433aa4ac87d4816ab0b9e4d78e905a0",
      "placeholder": "​",
      "style": "IPY_MODEL_2d78dfa173e94d07b83f91afa43abe04",
      "value": "100%"
     }
    },
    "264f02c1f4084040ba663543f17c9c4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2d78dfa173e94d07b83f91afa43abe04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b877c3e81cd43a4818268074831b9fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c9ced6d0d834d7793d75e572f640187": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "949ee989a20345ccb165075da7d1caec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_20b78c3161d7493ba26762ad7f8e5969",
       "IPY_MODEL_0c7c3cb36f714c41a242f4f467acdf6f",
       "IPY_MODEL_f88cfb35a12742deb5e1cedc17c8ab11"
      ],
      "layout": "IPY_MODEL_8c9ced6d0d834d7793d75e572f640187"
     }
    },
    "e1dd4b281da540eda30bf2186ec10eb0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f88cfb35a12742deb5e1cedc17c8ab11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1dd4b281da540eda30bf2186ec10eb0",
      "placeholder": "​",
      "style": "IPY_MODEL_5b877c3e81cd43a4818268074831b9fb",
      "value": " 528M/528M [00:03&lt;00:00, 199MB/s]"
     }
    },
    "faa72dcc176146b394c219898ccda2fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
